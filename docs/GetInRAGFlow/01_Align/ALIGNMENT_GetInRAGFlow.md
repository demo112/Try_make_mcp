# 阶段1：对齐 - GetInRAGFlow

## 1. 原始需求与背景
**用户输入**：
> 在执行评审工作流的过程中，会产生很多的待澄清点... 需要从原有的资料中找到这部分内容来解答新方案的待澄清点。此时就需要调用ragflow平台的知识库来查询相关的信息以做出澄清。同时，需要对检索以及回答的质量要有个评估和规范。
> 1、在查询前不仅携带该澄清点的所有内容，也要大模型总结上下文信息一起携带查询 
> 2、给这种由RAG提供信息，大模型回答的答案以独立的回答字段。与人工回答的信息不冲突。且以人工回答的信息为优先。
> 3、保证流程可靠执行而不是虚设流程。
> 4、当任何环节出现错误时自动重试并有退化策略。
> 5、任何环节，严禁：推断、捏造、编造，以生成任何虚假的信息。

**核心痛点**：
1.  **效率瓶颈**: 评审过程中产生的“待澄清点”依赖人工检索，效率低下且易遗漏。
2.  **知识污染**: 如果 RAG 检索了错误的上下文（如跨模块引用），会导致“幻觉”并在后续流程中污染新知识库。
3.  **流程虚设**: 传统的检查清单往往流于形式，缺乏强制性的技术卡点来确保执行质量。
4.  **上下文丢失**: 简单的关键词搜索往往丢失了项目背景和局部上下文，导致回答不准确。
5.  **系统脆弱性**: 缺乏重试和降级机制，一旦外部服务（如 RAGFlow）波动，整个工作流中断。

**业务目标**：
- **深度集成**: 将 RAGFlow 深度整合进 6A 工作流，使其成为“评审即知识管理”的核心引擎。
- **治理管控**: 通过强制元数据和红蓝对抗机制，确保知识的纯净性。
- **知识闭环**: 实现从“检索旧知识”到“沉淀新知识”的完整闭环，并具备晋升机制。
- **高鲁棒性**: 确保系统在外部依赖不稳定的情况下仍能提供降级服务，不阻塞核心流程。
- **绝对真实**: 严格控制模型输出，对于未检索到的信息明确告知，绝不编造。

## 2. 业务上下文分析
### 2.1 6A 工作流的演进
- **原状**: 线性流程，文档流转，人工评审，缺乏自动化辅助和质量强制。
- **目标状态**: 
    - **阶段 1 (对齐)**: 强制锚定知识边界（产品/模块范围）。
    - **阶段 3 (原子化)**: 智能代理 RAG 主动介入，提供基于上下文的建议。
    - **阶段 5 (自动化)**: 自动收割人工决策产生的新知识。
    - **阶段 6 (评估)**: 引入“红蓝对抗”和“架构师审批”作为强制卡点，决定知识是否晋升。

### 2.2 风险与缓解
- **幻觉风险**: 
    - *缓解*: 引入 **元数据锚定**，强制检索时携带产品/模块标签，物理隔离无关知识；**提示词约束**，严禁模型在无确凿依据时生成答案。
- **文件覆盖风险**:
    - *缓解*: 设立独立字段 `**AI 参考建议**`，严禁覆盖 `**回答**` 字段（该字段仅限人工填写）。
- **知识冲突风险**:
    - *缓解*: 在入库前执行 **红蓝对抗**，用新知识去攻击旧知识，若发现矛盾，必须人工介入解决。
- **服务可用性风险**:
    - *缓解*: 引入 **自动重试** (Exponential Backoff) 和 **降级策略** (如 RAG 失败则仅进行关键词匹配或提示人工手动查询)。

## 3. 核心能力定义
1.  **智能检索引擎 (Inference Engine)**: 
    - **能力**: 基于上下文的 RAG 检索。
    - **特性**: 支持全局+局部上下文融合；具备查询重写和自修正能力；**失败自动重试**。
2.  **治理管控引擎 (Governance Engine)**:
    - **能力**: 元数据检查与冲突检测。
    - **特性**: 强制检查文档元数据；执行新旧知识冲突检测；**真实性校验**。
3.  **生命周期引擎 (Lifecycle Engine)**:
    - **能力**: 知识提取、晋升与同步。
    - **特性**: 自动提取评审结论；生成晋升审批单；执行跨库同步；**知识库查询与浏览**。
4.  **方案进化引擎 (Evolution Engine)**:
    - **能力**: 方案文档自动迭代。
    - **特性**: 基于澄清结果自动修订方案文档；保持文档版本一致性。

## 5. 生产环境升级 (v2.1 P0 计划)
**背景**: 为了将 GetInRAGFlow 打造为团队级生产力基础设施，需解决文档修改的破坏性风险、并发冲突和质量稳定性问题。

### 5.1 核心需求
1.  **稳健性升级 (Robustness)**:
    *   **现状**: 依赖 LLM 文本重写，易破坏 Markdown 结构（表格、Mermaid）。
    *   **目标**: 引入 **Markdown AST (抽象语法树)** 解析库。
    *   **规范**: 文档修改必须是结构化的（如“替换第3个H2下的第1个表格”），严禁全文模糊重写。

2.  **轻量级副本机制 (Collaboration)**:
    *   **现状**: 直接修改工作区文件，存在并发冲突和误操作风险。
    *   **目标**: 在本地生成带时间戳的副本文件，避免覆盖原内容。
    *   **规范**: 所有的自动化修改（进化、填充）必须输出到同目录下 `{原文件名}-ai-{timestamp}.md`，绝不触碰原文件；用户可一键对比或手动合并。
    

3.  **测试左移 (Quality Assurance)**:
    *   **现状**: 缺乏对推理引擎质量的自动化回归测试。
    *   **目标**: 构建 **黄金数据集 (Golden Dataset)** 和集成测试流水线。
    *   **规范**: 每次代码变更后，必须自动运行 `tests/test_inference_quality.py`，确保对 20+ 个核心问题的回答准确率（语义相似度）不低于基准线 (0.8)。

### 5.2 风险评估
*   **Git 依赖**: 运行环境必须安装 Git 且配置了用户身份。若无 Git 环境，需降级为“仅修改文件但不提交”或报错。
*   **AST 复杂度**: 解析复杂的 Markdown（尤其是混合 HTML 的情况）可能存在兼容性问题。需选用成熟库 (如 `mistune` 或 `markdown-it-py` 的 AST 模式)。

